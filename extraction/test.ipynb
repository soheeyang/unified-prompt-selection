{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gimmaru/opt/miniconda3/envs/your-prompt/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "05/10/2023 02:40:38 - INFO - evaluator - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cpu\n",
      "Mixed precision type: no\n",
      "\n",
      "05/10/2023 02:40:41 - WARNING - datasets.builder - Found cached dataset glue (/Users/gimmaru/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "05/10/2023 02:40:41 - WARNING - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /Users/gimmaru/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-6110398b2a0d12ba.arrow\n",
      "loading configuration file config.json from cache at /Users/gimmaru/.cache/huggingface/hub/models--facebook--opt-125m/snapshots/3d2b5f275bdf882b8775f902e1bfdb790e2cfc32/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-125m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 3072,\n",
      "  \"hidden_size\": 768,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 768\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/gimmaru/.cache/huggingface/hub/models--facebook--opt-125m/snapshots/3d2b5f275bdf882b8775f902e1bfdb790e2cfc32/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-125m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 3072,\n",
      "  \"hidden_size\": 768,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 768\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /Users/gimmaru/.cache/huggingface/hub/models--facebook--opt-125m/snapshots/3d2b5f275bdf882b8775f902e1bfdb790e2cfc32/vocab.json\n",
      "loading file merges.txt from cache at /Users/gimmaru/.cache/huggingface/hub/models--facebook--opt-125m/snapshots/3d2b5f275bdf882b8775f902e1bfdb790e2cfc32/merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /Users/gimmaru/.cache/huggingface/hub/models--facebook--opt-125m/snapshots/3d2b5f275bdf882b8775f902e1bfdb790e2cfc32/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/gimmaru/.cache/huggingface/hub/models--facebook--opt-125m/snapshots/3d2b5f275bdf882b8775f902e1bfdb790e2cfc32/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/gimmaru/.cache/huggingface/hub/models--facebook--opt-125m/snapshots/3d2b5f275bdf882b8775f902e1bfdb790e2cfc32/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-125m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 3072,\n",
      "  \"hidden_size\": 768,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 768\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/gimmaru/.cache/huggingface/hub/models--facebook--opt-125m/snapshots/3d2b5f275bdf882b8775f902e1bfdb790e2cfc32/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-125m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 3072,\n",
      "  \"hidden_size\": 768,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 768\n",
      "}\n",
      "\n",
      "05/10/2023 02:40:43 - INFO - model.decoder - Building DecoderModel\n",
      "loading weights file pytorch_model.bin from cache at /Users/gimmaru/.cache/huggingface/hub/models--facebook--opt-125m/snapshots/3d2b5f275bdf882b8775f902e1bfdb790e2cfc32/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.27.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing OPTForCausalLM.\n",
      "\n",
      "All the weights of OPTForCausalLM were initialized from the model checkpoint at facebook/opt-125m.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use OPTForCausalLM for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /Users/gimmaru/.cache/huggingface/hub/models--facebook--opt-125m/snapshots/3d2b5f275bdf882b8775f902e1bfdb790e2cfc32/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.27.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running template prompt_00 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.00ba/s]\n",
      "05/10/2023 02:40:48 - INFO - evaluator - Sample 20 of the training set: {'input_ids': [[2, 405, 12419, 390, 101, 39984, 479, 1437, 20, 5702, 9, 42, 3645, 16], [2, 405, 12419, 390, 101, 39984, 479, 1437, 20, 5702, 9, 42, 3645, 16]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[2430], [1313]], 'labels_attention_mask': [[1], [1]], 'targets': 0}.\n",
      "05/10/2023 02:40:48 - INFO - evaluator - Sample 3 of the training set: {'input_ids': [[2, 438, 1343, 128, 29, 12456, 9, 3528, 8, 5, 657, 9, 11605, 12, 463, 12, 13367, 3649, 1085, 540, 87, 10, 92, 2236, 14, 8613, 7, 28, 1687, 25, 10, 678, 10359, 7, 5, 275, 2287, 2379, 260, 5392, 479, 1437, 20, 5702, 9, 42, 3645, 16], [2, 438, 1343, 128, 29, 12456, 9, 3528, 8, 5, 657, 9, 11605, 12, 463, 12, 13367, 3649, 1085, 540, 87, 10, 92, 2236, 14, 8613, 7, 28, 1687, 25, 10, 678, 10359, 7, 5, 275, 2287, 2379, 260, 5392, 479, 1437, 20, 5702, 9, 42, 3645, 16]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[2430], [1313]], 'labels_attention_mask': [[1], [1]], 'targets': 1}.\n",
      "05/10/2023 02:40:48 - INFO - evaluator - Sample 0 of the training set: {'input_ids': [[2, 405, 1516, 2500, 5, 2441, 95, 59, 25, 203, 9, 5, 117, 548, 5104, 25, 65, 115, 15646, 1057, 2156, 8, 16, 20407, 14500, 154, 8, 1375, 11, 63, 308, 235, 479, 1437, 20, 5702, 9, 42, 3645, 16], [2, 405, 1516, 2500, 5, 2441, 95, 59, 25, 203, 9, 5, 117, 548, 5104, 25, 65, 115, 15646, 1057, 2156, 8, 16, 20407, 14500, 154, 8, 1375, 11, 63, 308, 235, 479, 1437, 20, 5702, 9, 42, 3645, 16]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[2430], [1313]], 'labels_attention_mask': [[1], [1]], 'targets': 1}.\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.86ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 117.52ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 133.43ba/s]\n",
      "/Users/gimmaru/lk_lab/t-zero/evaluation/utils.py:340: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric_acc = load_metric(\"accuracy\")\n",
      "05/10/2023 02:40:57 - INFO - evaluator - ***** Running evaluation *****\n",
      "05/10/2023 02:40:57 - INFO - evaluator -   Num examples = 24\n",
      "05/10/2023 02:40:57 - INFO - evaluator -   Instantaneous batch size per device = 8\n",
      "05/10/2023 02:40:57 - INFO - evaluator -   Total eval batch size (w. parallel, distributed) = 8\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 3/3 [00:11<00:00,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'accuracy': 0.7083333333333334}\n",
      "Result: {'f1': 0.6307692307692307}\n",
      "***** Running template prompt_23 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.07ba/s]\n",
      "05/10/2023 02:41:11 - INFO - evaluator - Sample 6 of the training set: {'input_ids': [[2, 6209, 22, 627, 822, 19764, 88, 10, 12903, 14, 115, 483, 10, 313, 420, 11505, 479, 22, 9, 10, 2430, 50, 1313, 5702, 116], [2, 6209, 22, 627, 822, 19764, 88, 10, 12903, 14, 115, 483, 10, 313, 420, 11505, 479, 22, 9, 10, 2430, 50, 1313, 5702, 116]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[2430], [1313]], 'labels_attention_mask': [[1], [1]], 'targets': 1}.\n",
      "05/10/2023 02:41:11 - INFO - evaluator - Sample 20 of the training set: {'input_ids': [[2, 6209, 22, 405, 12419, 390, 101, 39984, 479, 22, 9, 10, 2430, 50, 1313, 5702, 116], [2, 6209, 22, 405, 12419, 390, 101, 39984, 479, 22, 9, 10, 2430, 50, 1313, 5702, 116]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[2430], [1313]], 'labels_attention_mask': [[1], [1]], 'targets': 0}.\n",
      "05/10/2023 02:41:11 - INFO - evaluator - Sample 15 of the training set: {'input_ids': [[2, 6209, 22, 260, 542, 4684, 1594, 37217, 11522, 892, 11, 1403, 111, 8, 2437, 12, 33045, 479, 22, 9, 10, 2430, 50, 1313, 5702, 116], [2, 6209, 22, 260, 542, 4684, 1594, 37217, 11522, 892, 11, 1403, 111, 8, 2437, 12, 33045, 479, 22, 9, 10, 2430, 50, 1313, 5702, 116]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[2430], [1313]], 'labels_attention_mask': [[1], [1]], 'targets': 0}.\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.39ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.24ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.36ba/s]\n",
      "05/10/2023 02:41:20 - INFO - evaluator - ***** Running evaluation *****\n",
      "05/10/2023 02:41:20 - INFO - evaluator -   Num examples = 24\n",
      "05/10/2023 02:41:20 - INFO - evaluator -   Instantaneous batch size per device = 8\n",
      "05/10/2023 02:41:20 - INFO - evaluator -   Total eval batch size (w. parallel, distributed) = 8\n",
      "100%|██████████| 3/3 [00:23<00:00,  7.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'accuracy': 0.4166666666666667}\n",
      "Result: {'f1': 0.29411764705882354}\n",
      "***** Running template prompt_83 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.44ba/s]\n",
      "05/10/2023 02:41:37 - INFO - evaluator - Sample 23 of the training set: {'input_ids': [[2, 2264, 16, 5, 5702, 2327, 11, 5, 511, 445, 116, 2430, 50, 1313, 4, 22, 627, 94, 291, 728, 32, 5568, 24670, 154, 2156, 53, 144, 9, 5, 1569, 16, 5, 276, 9231, 38187, 260, 921, 12, 30674, 385, 27313, 52, 128, 548, 450, 137, 111, 129, 42, 86, 47, 33, 7, 1166, 5, 36762, 11248, 22], [2, 2264, 16, 5, 5702, 2327, 11, 5, 511, 445, 116, 2430, 50, 1313, 4, 22, 627, 94, 291, 728, 32, 5568, 24670, 154, 2156, 53, 144, 9, 5, 1569, 16, 5, 276, 9231, 38187, 260, 921, 12, 30674, 385, 27313, 52, 128, 548, 450, 137, 111, 129, 42, 86, 47, 33, 7, 1166, 5, 36762, 11248, 22]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[2430], [1313]], 'labels_attention_mask': [[1], [1]], 'targets': 0}.\n",
      "05/10/2023 02:41:37 - INFO - evaluator - Sample 22 of the training set: {'input_ids': [[2, 2264, 16, 5, 5702, 2327, 11, 5, 511, 445, 116, 2430, 50, 1313, 4, 22, 282, 8370, 2156, 6590, 9684, 99, 128, 29, 164, 7, 146, 82, 7923, 2156, 1237, 5, 20577, 1182, 31, 37367, 32806, 7, 910, 28507, 219, 2099, 821, 8299, 7, 9288, 8728, 5313, 479, 22], [2, 2264, 16, 5, 5702, 2327, 11, 5, 511, 445, 116, 2430, 50, 1313, 4, 22, 282, 8370, 2156, 6590, 9684, 99, 128, 29, 164, 7, 146, 82, 7923, 2156, 1237, 5, 20577, 1182, 31, 37367, 32806, 7, 910, 28507, 219, 2099, 821, 8299, 7, 9288, 8728, 5313, 479, 22]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[2430], [1313]], 'labels_attention_mask': [[1], [1]], 'targets': 0}.\n",
      "05/10/2023 02:41:37 - INFO - evaluator - Sample 6 of the training set: {'input_ids': [[2, 2264, 16, 5, 5702, 2327, 11, 5, 511, 445, 116, 2430, 50, 1313, 4, 22, 627, 822, 19764, 88, 10, 12903, 14, 115, 483, 10, 313, 420, 11505, 479, 22], [2, 2264, 16, 5, 5702, 2327, 11, 5, 511, 445, 116, 2430, 50, 1313, 4, 22, 627, 822, 19764, 88, 10, 12903, 14, 115, 483, 10, 313, 420, 11505, 479, 22]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[2430], [1313]], 'labels_attention_mask': [[1], [1]], 'targets': 1}.\n",
      "100%|██████████| 1/1 [00:00<00:00, 119.49ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.19ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.69ba/s]\n",
      "05/10/2023 02:41:43 - INFO - evaluator - ***** Running evaluation *****\n",
      "05/10/2023 02:41:43 - INFO - evaluator -   Num examples = 24\n",
      "05/10/2023 02:41:43 - INFO - evaluator -   Instantaneous batch size per device = 8\n",
      "05/10/2023 02:41:43 - INFO - evaluator -   Total eval batch size (w. parallel, distributed) = 8\n",
      "100%|██████████| 3/3 [00:23<00:00,  7.69s/it]\n",
      "100%|██████████| 3/3 [00:12<00:00,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'accuracy': 0.6666666666666666}\n",
      "Result: {'f1': 0.6571428571428571}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluator import EvaluatorForZeroshot\n",
    "\n",
    "class args:\n",
    "    dataset_name = \"super_glue\"\n",
    "    dataset_config_name = \"copa\"\n",
    "    template_name = \"prompt_00,prompt_23\"\n",
    "    max_length = 1024\n",
    "    target_max_length = 256\n",
    "    model_name_or_path = \"facebook/opt-125m\"\n",
    "    config_name = None\n",
    "    tokenizer_name = None\n",
    "    use_slow_tokenizer = False\n",
    "    per_device_eval_batch_size = 8\n",
    "    output_dir = \"test\"\n",
    "    result_dir = \"./results\"\n",
    "    parallelize = False\n",
    "    empty_input = \",N/A,[MASK]\"\n",
    "    ignore_index = 1\n",
    "    seed = 42\n",
    "    num_samples = 24\n",
    "    sum_log_prob = True\n",
    "    otr = False\n",
    "\n",
    "evaluator = EvaluatorForZeroshot(args)\n",
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "your-prompt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
